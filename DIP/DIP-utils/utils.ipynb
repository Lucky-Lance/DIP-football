{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "#from sklearn import datasets\n",
    "from sklearn.datasets import load_iris\n",
    "from moviepy.editor import *\n",
    "from box_utils import compute_IOU\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RED = (255, 0, 0)\n",
    "GREEN = (0, 255, 0)\n",
    "BLUE = (0, 0, 255)\n",
    "CYAN = (0, 255, 255)\n",
    "YELLOW = (255, 255, 0)\n",
    "ORANGE = (255, 165, 0)\n",
    "PURPLE = (255, 0, 255)\n",
    "WHITE = (255, 255, 255)\n",
    "BLACK = (0, 0, 0)\n",
    "PART_COLOR_LIST = [GREEN, CYAN, YELLOW, ORANGE, PURPLE, RED]\n",
    "\n",
    "BROWN = (128, 42, 42)\n",
    "JACKIE_BLUE = (11, 23, 70)\n",
    "YELLOW_BROWN = (240, 230, 140)\n",
    "SOMECOLOR = (255, 127, 127)\n",
    "STRAWBERRY = (135, 38, 87)\n",
    "DARKGREEN = (48, 128, 20)\n",
    "ID_COLOR_LIST = [DARKGREEN, BROWN, STRAWBERRY, JACKIE_BLUE, BLUE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first get all the human box\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_file = open(\"./fix_video.txt\")\n",
    "human_box_all = {}\n",
    "for line in yolo_file:\n",
    "    line = line.rstrip(\"\\n\").split(\" \")\n",
    "    frame_idx, human_idx, x_min, y_min, x_delta, y_delta, _, _, _, _, _ = line\n",
    "    frame_idx, human_idx, x_min, y_min, x_delta, y_delta = int(frame_idx), int(human_idx), int(x_min), int(y_min), int(x_delta), int(y_delta)\n",
    "    if frame_idx not in human_box_all:\n",
    "        human_box_all[frame_idx] = {}\n",
    "    if human_idx not in human_box_all[frame_idx]:\n",
    "        human_box_all[frame_idx][human_idx] = {}\n",
    "    human_box_all[frame_idx][human_idx][\"bbox\"] = np.array([x_min, y_min, x_min + x_delta, y_min + y_delta]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./human_box_yolo.pkl\", \"wb\") as file_yolo:\n",
    "    pickle.dump(human_box_all, file_yolo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PaStaNet param\n",
    "pasta_name_list = np.array([x.strip() for x in open(\"./PaStaNet-Data/Part_State_93_new.txt\").readlines()])\n",
    "verb_name_list = np.array([x.strip() for x in open(\"./PaStaNet-Data/verb_list_new.txt\").readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_verbs = [57, 146]\n",
    "excluded_verb_names = np.delete(verb_name_list, excluded_verbs, axis=0)\n",
    "topk = 5\n",
    "SCORE_THRES = 1.5\n",
    "FONT_SIZE = 18\n",
    "WHITE = (255, 255, 255)\n",
    "font = ImageFont.truetype(\"../tools/inference_tools/consola.ttf\", FONT_SIZE)\n",
    "font_player = ImageFont.truetype(\"../tools/inference_tools/consola.ttf\", 2 * FONT_SIZE)\n",
    "MAX_HUMAN_NUM = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_sample = pickle.load(open(\"./res/1.pkl\", \"rb\"))\n",
    "# print(pickle_sample['p_verb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = \"../DemoVideo/fix_video.mp4\"\n",
    "cap = cv2.VideoCapture(video_name)\n",
    "speed = cap.get(5)\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    if frame is not None:\n",
    "        x_range = len(frame[0])\n",
    "        y_range = len(frame)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# human_box_all\n",
    "frame_list = []\n",
    "blank_image = np.zeros_like(frame)\n",
    "for frame_idx in tqdm(human_box_all):\n",
    "    frame_box = human_box_all[frame_idx]\n",
    "    h2v_pkl_path = \"./res/\" + str(frame_idx) + \".pkl\"\n",
    "    if os.path.exists(h2v_pkl_path) == False:\n",
    "        continue\n",
    "    image = cv2.cvtColor(blank_image, cv2.COLOR_BGR2RGB)\n",
    "    im_shape = list(image.shape)\n",
    "\n",
    "    # Construct a black sidebar.\n",
    "    ones_shape = copy.deepcopy(im_shape)\n",
    "    # a broader side\n",
    "    ones_shape[1] = 80 * (MAX_HUMAN_NUM // 5 + 1)\n",
    "    image_ones = np.ones(ones_shape, dtype=image.dtype) * 0\n",
    "    image = np.concatenate((image, image_ones), axis=1)\n",
    "    \n",
    "    pil_image = Image.fromarray(image).convert('RGBA')\n",
    "\n",
    "    h2v_pkl = pickle.load(open(h2v_pkl_path, \"rb\"))\n",
    "    h2v_human_boxes = np.array(h2v_pkl['human_bboxes'])\n",
    "    h2v_scores = h2v_pkl['human_scores'][:, 0]\n",
    "\n",
    "    score_filter = h2v_scores > SCORE_THRES\n",
    "    \n",
    "    h2v_human_boxes = h2v_human_boxes[score_filter]\n",
    "    p_verb = h2v_pkl['p_verb']\n",
    "    \n",
    "    # White rectangle as bottom.\n",
    "    overlay = Image.new('RGBA', pil_image.size, WHITE+(0,))\n",
    "    overlay_draw = ImageDraw.Draw(overlay)\n",
    "    \n",
    "    canvas = Image.new('RGBA', pil_image.size, WHITE+(0,))\n",
    "    draw = ImageDraw.Draw(canvas)\n",
    "\n",
    "    extra_offset = FONT_SIZE\n",
    "    # print(len(h2v_human_boxes))\n",
    "    human_action_yolo = {}\n",
    "    human_count = 0\n",
    "    for human_key in frame_box: # the index of yolo\n",
    "        \n",
    "        yolo_box = frame_box[human_key]['bbox']\n",
    "        x_min, y_min, x_max, y_max = yolo_box\n",
    "        center_x, center_y = (x_min + x_max) // 2, (y_min + y_max) // 2\n",
    "        IOU_list = []\n",
    "        # get the biggest one, (if bigger than 0.5)\n",
    "        for h2v_human_idx in range(len(h2v_human_boxes)):\n",
    "            h2v_human_box = h2v_human_boxes[h2v_human_idx]\n",
    "            # seach h2v for each yolo\n",
    "            IOU_list.append(compute_IOU(yolo_box, h2v_human_box))\n",
    "        \n",
    "        h2v_human_idx = np.argmax(IOU_list)\n",
    "        # if  IOU_list[h2v_human_idx] > 0.5: # optional\n",
    "        verb_scores = p_verb[h2v_human_idx] \n",
    "        # Get verb and pasta names to draw.\n",
    "        verb_scores = np.delete(verb_scores, excluded_verbs, axis=0)\n",
    "        verb_top_idxs = np.argsort(verb_scores)[::-1]\n",
    "        verb_draw_names = []\n",
    "        for top_idx, verb_name in enumerate(excluded_verb_names[verb_top_idxs]):\n",
    "            verb_idx = verb_top_idxs[top_idx]\n",
    "            if verb_name not in verb_draw_names:\n",
    "                verb_draw_names.append(verb_name)\n",
    "            if len(verb_draw_names) == topk:\n",
    "                break\n",
    "        human_action_yolo[human_key] = verb_draw_names\n",
    "\n",
    "        # draw one frame    \n",
    "        x_space = center_x - 19\n",
    "        y_space = center_y + 19\n",
    "        if human_key >= 10:\n",
    "            fontsize = 1\n",
    "            y_space = y_space - 3\n",
    "        # cv2.circle(\n",
    "        #     pil_image, (center_x, center_y), 30, (255, 255, 255), 2)\n",
    "        draw.text((x_space, y_space), str(human_key), font=font_player, fill=CYAN+(255, ))\n",
    "\n",
    "        # Update sidebar. @ XudongLu dynamic bar width\n",
    "        x_axis = x_range + 1 + (human_count // 5) * 80\n",
    "        if human_count % 5 == 0:\n",
    "            extra_offset = 0\n",
    "        \n",
    "        draw.text((x_axis, 3+extra_offset), 'ID: '+str(human_key), font=font, fill=CYAN+(255, ))  # +' {:.3f}'.format(verb_scores[verb_idx])\n",
    "        \n",
    "        extra_offset += FONT_SIZE + 2\n",
    "        for draw_name in verb_draw_names:\n",
    "            # x_axis = im_shape[1]+1\n",
    "            draw.text((x_axis, 3+extra_offset), draw_name, font=font, fill=GREEN+(255, ))  # +' {:.3f}'.format(verb_scores[verb_idx])\n",
    "            extra_offset += FONT_SIZE\n",
    "        draw.text((x_axis, 3+extra_offset), '────────', font=font, fill=CYAN+(255, ))\n",
    "        extra_offset += FONT_SIZE\n",
    "        human_count = human_count + 1\n",
    "\n",
    "    # Combine image and canvas\n",
    "    pil_image = Image.alpha_composite(pil_image, overlay)\n",
    "    pil_image = Image.alpha_composite(pil_image, canvas)\n",
    "    pil_image = pil_image.convert('RGB')\n",
    "    cv2_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n",
    "    frame_list.append(cv2_image)\n",
    "\n",
    "new_clip = ImageSequenceClip(frame_list, fps=(int)(speed))\n",
    "vis_path = \"test_out.mp4\"\n",
    "new_clip.write_videofile(vis_path)\n",
    "print(len(frame_list))\n",
    "print(\"Team identification finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate action embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "actions = []\n",
    "json_data = json.load(open(\"./human_action.json\", \"r\"))\n",
    "for frame_idx in json_data:\n",
    "    for human_idx in json_data[frame_idx]:\n",
    "        actions.append(json_data[frame_idx][human_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(actions)):\n",
    "    actions[idx] = np.sort(np.array(actions[idx])).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "verblist_txt = open(\"./PaStaNet-Data/verb_list_new.txt\", \"r\")\n",
    "verblist = verblist_txt.readlines()\n",
    "verblist_dict = {}\n",
    "idx2verb = {}\n",
    "for idx in range(len(verblist)):\n",
    "    line = verblist[idx].rstrip(\"\\n\")\n",
    "    verblist_dict[line] = idx\n",
    "    idx2verb[idx] = line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./verblist2idx.pkl\", \"wb\") as verbfile:\n",
    "    pickle.dump(verblist_dict, verbfile)\n",
    "with open(\"./idx2verblist.pkl\", \"wb\") as verbfile:\n",
    "    pickle.dump(idx2verb, verbfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_dict = []\n",
    "for action in actions:\n",
    "    string = []\n",
    "    for clip in action:\n",
    "        string.append(verblist_dict[clip])\n",
    "    string = np.sort(np.array(string)).tolist()\n",
    "    action_dict.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n"
     ]
    }
   ],
   "source": [
    "# print(len(action_dict))\n",
    "# print(action_dict)\n",
    "news_ids = []\n",
    "for id in action_dict:\n",
    "    if id not in news_ids:\n",
    "        news_ids.append(id)\n",
    "print(len(news_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def cosine_distance(a, b):\n",
    "    if a.shape != b.shape:\n",
    "        raise RuntimeError(\"array {} shape not match {}\".format(a.shape, b.shape))\n",
    "    if a.ndim==1:\n",
    "        a_norm = np.linalg.norm(a)\n",
    "        b_norm = np.linalg.norm(b)\n",
    "    elif a.ndim==2:\n",
    "        a_norm = np.linalg.norm(a, axis=1, keepdims=True)\n",
    "        b_norm = np.linalg.norm(b, axis=1, keepdims=True)\n",
    "    else:\n",
    "        raise RuntimeError(\"array dimensions {} not right\".format(a.ndim))\n",
    "    similiarity = np.dot(a, b.T)/(a_norm * b_norm)\n",
    "    dist = 1. - similiarity\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_actions = []\n",
    "for new_ids in news_ids:\n",
    "    action_list = []\n",
    "    for idx in new_ids:\n",
    "        action_list.append(idx2verb[idx])\n",
    "    new_actions.append(action_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "bin_path = \"/Disk8/yonglu/Sandwich/Data/GoogleNews-vectors-negative300.bin\" \n",
    "w2v_model = KeyedVectors.load_word2vec_format(bin_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from football_action import football_action\n",
    "skill = football_action['skill']\n",
    "fight = football_action['fight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chesting\n",
      "interception\n",
      "interception\n",
      "chesting\n",
      "chesting\n",
      "chesting\n",
      "chesting\n",
      "chesting\n",
      "chesting\n",
      "diving header\n",
      "chesting\n",
      "interception\n",
      "interception\n",
      "interception\n",
      "chesting\n",
      "chesting\n",
      "interception\n",
      "interception\n",
      "interception\n",
      "interception\n",
      "goalkeeping\n",
      "chesting\n",
      "chesting\n",
      "chesting\n",
      "interception\n",
      "interception\n",
      "interception\n",
      "chesting\n",
      "interception\n",
      "chesting\n",
      "chesting\n",
      "goalkeeping\n",
      "interception\n",
      "man to man defence\n",
      "chesting\n",
      "man to man defence\n",
      "interception\n",
      "man to man defence\n",
      "trapping\n",
      "interception\n",
      "chesting\n",
      "interception\n",
      "goalkeeping\n",
      "trapping\n",
      "trapping\n",
      "man to man defence\n",
      "chesting\n",
      "goalkeeping\n",
      "chesting\n",
      "goalkeeping\n",
      "man to man defence\n",
      "chesting\n",
      "man to man defence\n",
      "support\n",
      "interception\n",
      "man to man defence\n",
      "interception\n",
      "goalkeeping\n",
      "interception\n",
      "trapping\n",
      "goalkeeping\n",
      "chesting\n",
      "chesting\n",
      "interception\n",
      "to intercept\n",
      "chesting\n",
      "chesting\n",
      "goalkeeping\n",
      "chesting\n",
      "goalkeeping\n",
      "goalkeeping\n",
      "chesting\n",
      "chesting\n",
      "trapping\n",
      "chesting\n",
      "man to man defence\n",
      "interception\n",
      "trapping\n",
      "man to man defence\n",
      "man to man defence\n",
      "interception\n",
      "man to man defence\n",
      "man to man defence\n",
      "trapping\n",
      "chesting\n",
      "to intercept\n",
      "interception\n",
      "chesting\n",
      "goalkeeping\n",
      "interception\n",
      "chesting\n",
      "interception\n",
      "interception\n",
      "goalkeeping\n",
      "goalkeeping\n",
      "interception\n",
      "support\n",
      "goalkeeping\n",
      "chesting\n",
      "interception\n",
      "interception\n",
      "interception\n",
      "chesting\n",
      "goalkeeping\n",
      "interception\n",
      "goalkeeping\n",
      "interception\n",
      "trapping\n",
      "goalkeeping\n",
      "chesting\n",
      "interception\n",
      "interception\n",
      "interception\n",
      "support\n",
      "goalkeeping\n",
      "goalkeeping\n",
      "interception\n",
      "to disorganize the defence\n",
      "interception\n",
      "interception\n",
      "goalkeeping\n",
      "interception\n",
      "goalkeeping\n",
      "interception\n",
      "goalkeeping\n",
      "interception\n",
      "interception\n",
      "chesting\n",
      "goalkeeping\n"
     ]
    }
   ],
   "source": [
    "for new_action in new_actions:\n",
    "    cos_score = []\n",
    "    action_vector = []\n",
    "    for action in new_action:\n",
    "        action_vector.append(w2v_model[action])\n",
    "    action_vector = np.vstack(action_vector)\n",
    "    # vector = np.sum(vector,axis=0)\n",
    "    action_vector = np.mean(action_vector,axis=0)\n",
    "    for action in skill:\n",
    "        action_vect_map = []\n",
    "        # w2v_model\n",
    "        action = action.replace(\"_\", ' ')\n",
    "        action = action.replace(\"-\", ' ')\n",
    "        action = action.replace(\".\", ' ')\n",
    "        action = action.replace(\",\", ' ')\n",
    "        action_list = action.split(\" \")\n",
    "        for action_clip in action_list:\n",
    "            if action_clip not in w2v_model:\n",
    "                continue\n",
    "            action_vect_map.append(w2v_model[action_clip])\n",
    "        if len(action_vect_map) > 0:\n",
    "            action_vect_map = np.vstack(action_vect_map)\n",
    "            action_vect_map = np.mean(action_vect_map,axis=0)\n",
    "            cos_score.append(cosine_distance(action_vector, action_vect_map))\n",
    "        else:\n",
    "            cos_score.append(0.)\n",
    "    skill_idx = np.argmax(cos_score)\n",
    "    print(skill[skill_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.metrics\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([3, 2, 1])\n",
    "dis = cosine_distance(a, b)\n",
    "print(dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for action in fight:\n",
    "    # w2v_model\n",
    "    action = action.replace(\"_\", ' ')\n",
    "    action = action.replace(\"-\", ' ')\n",
    "    action = action.replace(\"-\", ' ')\n",
    "    action = action.replace(\",\", ' ')\n",
    "    action_list = action.split(\" \")\n",
    "    # print(action_list)\n",
    "    for action_clip in action_list:\n",
    "        if action_clip not in w2v_model:\n",
    "            continue\n",
    "        w2v_model[action_clip]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56b8f11a7165b6790b25e21d45460f384a5522a1858e3ac13a5f91c00acd385f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('activity2vec': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
